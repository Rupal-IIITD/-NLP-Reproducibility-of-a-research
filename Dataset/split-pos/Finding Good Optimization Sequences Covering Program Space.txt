Finding good optimization sequences covering program space

by

Suresh Purini

in

ACM Transactions on Architecture and Code Optimization

Report No: IIIT/TR/2013/-1

Centre for VLSI and Embeded Systems Technology

International Institute of Information Technology

Hyderabad - 500 032, INDIA

January 2013

Finding Good Optimization Sequences Covering Program Space

Suresh Purini, International Institute of Information Technology, Hyderabad, India
Lakshya Jain, International Institute of Information Technology, Hyderabad, India

39

The compiler optimizations we enable and the order in which we apply them on a program have a substantial
impact on the program execution time. Compilers provide default optimization sequences which can give
good program speedup. As the default sequences have to optimize programs with different characteristics,
they embed in them multiple subsequences which can optimize different classes of programs. These multiple
subsequences may falsely interact with each other and effect the potential program speedup achievable.
Instead of searching for a single universally optimal sequence, we can construct a small set of good sequences
such that for every program class there exists a near optimal optimization sequence in the good sequences
set. If we can construct such a good sequences set which covers all the program classes in the program
space, then we can choose the best sequence for a program by trying all the sequences in the good sequences
set. This approach completely circumvents the need to solve the program classiﬁcation problem. Using a
sequence set size of around 10 we got an average speedup up to 14 percent on PolyBench programs and up
to 12 percent on MiBench programs. Our approach is quite different from either the iterative compilation or
machine learning based prediction modelling techniques proposed in the literature so far. We use different
training and test data sets for cross validation as against the Leave-One-Out cross validation technique.

Additional Key Words and Phrases: Compiler Optimizations, Phase Ordering Problem, Optimization Se-
quence Clustering, Program Clustering.

1. INTRODUCTION

1.1. Motivation and Problem Deﬁnition
Modern optimizing compilers are organized as a sequence of three modules – front end,
optimizer (middle end) and back end (see Figure 1). The front end generates an inter-
mediate representation (IR) of the source program after checking for its syntactic and
semantic correctness. The optimizer component which constitutes the middle end of
the compiler applies a series of transformations on the IR so as to optimize it with re-
spect to parameters like speed, memory footprint, power etc. The back end translates
the optimized IR into target machine code and during that process it applies machine
dependent code optimizations [Torczon and Cooper 2011]. The optimizer component is

Fig. 1. Structure of a Three Phase Compiler

organized as a sequence of analysis and transformation passes. Analysis passes an-
alyze the program and collect necessary information required by the transformation
passes. A compiler optimization typically consists of one or more analysis passes fol-
lowed by a transformation pass. Any sequence of compiler optimizations that can act
on the program IR is called as an optimization sequence. The collection of all optimiza-
tion sequences is called the optimization sequence space and is inﬁnitely large. The

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:2

runtime1 of a program is a function of the optimization sequence applied on its IR.
Figure 2 shows the runtime for the program dynprog from the PolyBench 3.0 bench-
mark suite [Polybench 2012] on a set of 290 optimization sequences in a sorted order.
The methodology for choosing these 290 optimization sequences will be discussed in
detail in Section 3.3. The impact of the optimization sequences on the program run-
times can also be observed by computing the variance in the program runtimes when
optimized by bounded length sequences generated by a uniform random sampling of
the optimization sequence space.

Fig. 2. Runtimes of the program dynprog from the PolyBench suite when optimized using different opti-
mization sequences. X-axis is labeled with sequence numbers which are sorted according to the respective
program runtimes.

The optimization sequence space size grows exponentially as a function of sequence
length. If there are k optimizations, then there are kl optimization sequences of length
l. We say that an optimization sequence is optimal for a program if it leads to smallest
program runtime when compared to all other sequences. This deﬁnition is incomplete
as the program runtime and its behaviour could be a function of the input. So an opti-
mal sequence for a program depends on the program characteristics as deﬁned by the
input to the program. However in this work we assume that a program has a canonical
input distribution and the program characteristics with respect to that input distribu-
tion almost remains constant [Chen et al. 2010]. If this assumption is not valid, then
the sequence chosen using a particular input may not be good when the program is run
using inputs which induce different program characteristics. The problem of ﬁnding an
optimal optimization sequence for a program from the inﬁnitely large optimization se-
quence space is called as the phase order search problem. As the phase order search
problem is a combinatorial search problem with no linearity or convexity properties,
we cannot say whether a given sequence is optimal. All we can say is how well the
sequence is performing with respect to a default compiler optimization sequence (like
-O2). When we say that a sequence is good for a program, it only means that it is
giving a noticeable performance improvement over default optimization sequences. A
good sequence is not necessarily an optimal sequence.

1.2. Summary of Proposed Approach
Searching a good optimization sequence for a program in the optimization sequence
space is like searching for a needle in a haystack. Instead of solving this problem on a
per program basis, compiler writers construct good optimization sequences through ex-
perience and experimentation on benchmark programs. The constructed sequences are

1In this paper, program runtime is the only performance parameter we consider.

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:3

associated with default optimization options like -O1, -O2 and - O32. These sequences
may be globally optimal with respect to the program space3, but are sub-optimal for
the individual programs. The simple reason being what is a good sequence for one pro-
gram may not be good for another. So looking for an universal good sequence is a futile
exercise. An alternate viable approach which we proposed in this paper is, to build a set
of few good sequences, so that for every class of programs there exists a good optimiza-
tion sequence in the sequence set catering to that class. Then given a new program we
can choose the best sequence by trying out all the sequences from the good sequences
set. This approach completely bypasses the program classiﬁcation problem. Using the
LLVM compiler framework [Lattner and Adve 2004] we constructed a good sequences
set. In Section 3, the approach for constructing the good sequences set which forms the
crux of the proposed technique will be presented. Here we highlight the main contri-
butions of this paper.

(1) A downsampling technique to reduce the inﬁnitely large optimization sequence
space to a small set (of size in the order of hundreds). During the downsampling
process, the diversity of the optimization sequences catering to different program
classes will be retained.

(2) A sequence extraction algorithm to construct a small good sequences set from the
downsampled optimization sequence set, such that for every program class there
exists at least one good sequence in the reduced set. The size of the good sequences
set in our experiment is around 10.

(3) A sequence similarity metric and a sequence clustering algorithm leading to a al-
ternate approach for the good sequence set extraction from the downsampled se-
quence set.

(4) A program characterization approach using optimization sequences as against us-
ing static program features or dynamic features like hardware performance coun-
ters. This alternate perspective gives us a handle to understand the effectiveness
of optimization sequence prediction models and the relevant program features de-
termining the parameters of those models.

Our technique is quite different from the iterative compilation and machine learning
based prediction modeling methods proposed in the literature. In iterative compilation
techniques, a heuristic search algorithm4 is used to prune the optimization sequence
space to converge onto a good sequence. Even for very good heuristic techniques, the
number of required program evaluations would be prohibitively large to use in non-
trivial application programs. In the machine learning based approach, during an off-
line training phase the parameters of a chosen prediction model will be learnt by ob-
serving the runtimes of a set of sample programs5 when optimized using randomly
selected sequences. Then the prediction model would be used to determine the set of
optimizations that should be enabled on a given source program. A compiler speciﬁc
default ordering for the enabled optimizations would be used to optimize the program.
The principal advantage of this approach is that the number of required program eval-
uations would come down to feasible limits. Applying machine learning techniques to
directly predict the optimization sequences is not feasible because multi-label classi-

2These sequences have to be reconstructed whenever the back end of a compiler is retargeted to a new
processor architecture. This becomes a frequently recurring issue for compilers targeting embedded archi-
tectures.
3Program space consists of all syntactically and semantically valid programs.
4Genetic algorithms, simulated annealing, steepest descent methods are examples of heuristic search tech-
niques.
5These set of sample programs constitute the training data.

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:4

Table I. List of sixty two machine independent optimizations

List of Optimizations

-adce
-constmerge
-deadargelim
-globaldce
-inline
-ipconstprop
-loop-deletion
-loop-rotate
-loops
-lowerswitch
-partial-inliner
-sccp
-tailcallelim
-basicaa
-domtree
-memdep

-always-inline
-constprop
-die
-globalopt
-instcombine
-ipsccp
-loop-idiom
-loop-simplify
-lower-expect
-memcpyopt
-prune-eh
-simplify-libcalls
-targetlibinfo
-basiccg
-lazy-value-info
-strip-dead-prototypes

-argpromotion
-correlated-propagation
-dse
-gvn
-instsimplify
-jump-threading
-loop-instsimplify
-loop-unroll
-loweratomic
-mergefunc
-reassociate
-simplifycfg
-no-aa
-functionattrs
-lcssa

-codegenprepare
-dce
-early-cse
-indvars
-internalize
-licm
-loop-reduce
-loop-unswitch
-lowerinvoke
-mergereturn
-scalarrepl
-sink
-tbaa
-scalarrepl-ssa
-scalar-evolution

ﬁcation models like decision trees, neural networks etc. are suitable when there are
only few class labels. Thomson et al. [Thomson et al. 2009] proposed a nearest-cluster
approach to overcome this limitation. The set of available training programs are clus-
tered using their feature vectors and for each cluster center the best optimization se-
quence is obtained using an iterative compilation technique. For a new program the
sequence corresponding to the nearst cluster centroid is chosen as the best sequence.
Park et al. [Park et al. 2011] proposed a technique using tournament predictors for the
optimization sequence selection problem.

2. EXPERIMENTAL SETUP
We use the LLVM6 3.0 compiler infrastructure [Lattner and Adve 2004] to validate
the proposed approach. LLVM compiler infrastructure uses a persistent IR, and con-
sists of a collection of compiler tools and reusable libraries. We can store the IR of a
program on disk either in human readable text format or machine readable bitcode
format. The C language front end clang translates the source program into LLVM IR.
The middle end applies an optimization sequence on the IR based on the optimization
option (like -O1, -O2, -O3) chosen by the user. Then the the back end applies machine
dependent optimizations on the optimized IR and ﬁnally generates the target assem-
bly. The optimizations, register allocation and other algorithms invoked by the back
end are also dependent on the optimization level chosen by the user. Table I lists the
machine independent compiler optimizations invoked at -O2 level. Refer [LLVM 2012]
for a description of the optimizations listed in the Table I. In LLVM, the optimization
level -O2 almost always gives either better or equal performance as that of -O3. So in
all our experiments the performance comparison is with respect to -O2.

LLVM compiler infrastructure provides two tools, opt and llc, which are useful in
conducting our experiments. The opt program takes as input an optimization sequence
on the command line and applies it to the LLVM IR which is stored in a bitcode for-
mat ﬁle. After applying the speciﬁed optimization sequence, the transformed IR is
again written back to a ﬁle in bitcode format. llc translates an LLVM IR in a bitcode
ﬁle into target assembly code. We can invoke the back end of the compiler at various
optimization levels in isolation using llc. In this paper we focus on the interactions

6LLVM is an acronym for Low Level Virtual Machine

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:5

Fig. 3. Program Compilation Setup

between machine independent optimizations acting on the LLVM IR. The source pro-
gram is translated into unoptimized LLVM IR by ﬁrst by compiling it with clang at
-O0 level. Then -scalarrepl optimization is applied on the unoptimized IR. The scalar
replacement optimization transforms the LLVM IR into its SSA form suitable for any
other optimization to act upon. The opt tool applies the input optimization sequence7
on the IR and thereby generates the optimized IR. Finally llc transforms the LLVM
IR generated by the optimizer into target assembly code using -O2 level optimization.
For parametric optimizations like loop unrolling, we let the compiler choose the unroll
factor according to its own internal heuristics. Figure 3 depicts the summary of the
compilation process.

We used three benchmark suites in our experiments. The ﬁrst benchmark suite con-
sists of a collection of 61 programs from the LLVM test suite. We call this as the Mi-
crokernels benchmark suite. All the programs in the Microkernels suite are single ﬁle
short programs. We require the programs in this suite to have diverse characteristics
and short running times so that iterative compilation methods can be applied on them
to ﬁnd near optimal optimization sequences. So this suite contains sorting programs,
programs involving ﬂoating point arithmetic, programs containing tail recursion etc.
We use this suite in the off-line phase to prune the exponentially large optimization
sequence space down to a few good sequences. We test the effectiveness of our approach
on the MiBench [Guthaus et al. 2001] and the PolyBench [Polybench 2012] programs.
We use the data set one while running MiBench programs and the large data set for
the PolyBench programs.. We would like to highlight here that ours is the ﬁrst ap-
proach which uses completely different training and test data sets for cross validation
as against the widely used Leave-One-Out approach. All the experiments are carried
out on an Intel Xeon Processor W3550 machine with 12GB RAM.

3. PROPOSED APPROACH

3.1. Motivation
The set of good sequences for a program is a function of its characteristics (and the
target architecture). The key issue in machine learning based approaches is to iden-
tify the relevant static and dynamic program features characterizing a program with
respect to the optimization sequence selection problem and, an appropriate model cor-
relating the selected program features and the optimization sequences. Although some
compiler frameworks like Milepost GCC provides plugins to extract some static pro-
gram features, exploring the static program feature space is hard as addition of a
new static program feature to the existing set requires the source code modiﬁcation
of either an appropriate plug-in or the compiler itself. Instead we can use the hard-
ware performance counters provided by modern processors to capture the dynamic
behaviour of a program with relative ease. There could be sampling errors though
due to the large number of possible attributes to measure when compared with the

7There are no ordering constraints on the optimization passes in LLVM

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:6

available registers to accumulate the event counts. For accurate measurements we
have to run a program multiple times to reduce the sampling errors. However the
fundamental question what static, dynamic and possibly any other type of program
features completely characterize a program with respect to the optimization sequence
selection problem still remains largely open. Iterative compilation techniques which
does not use program features per se requires prohibitively large number of program
runs. The well known approach taken by all the major compilers is to precompute good
sequences and associate them with compilation options like -O1, -O2 and -O3. These
precomputed sequences are intended to be near optimal for diverse program classes. In
order to accomplish this, multiple subsequences catering to different program classes
are embedded into a single universally optimal sequence. However, the subsequences
within the bigger sequence may end up having false interactions and thereby adversely
impact the program run time. In essence a single size ﬁts all approach does not work
effectively.

An alternate approach is to identify the program classes and for each class we con-
struct a good optimization sequence either manually or by using an iterative com-
pilation technique like genetic algorithms. Then we can use a program classiﬁcation
algorithm to identify the class label for a new program and use the associated opti-
mization sequence for its compilation. The difﬁculty here, as discussed earlier, is in
identifying the program features and the program classiﬁcation model. Another prob-
lem in constructing good sequences for each of the program classes is in identifying
the criteria for program class representative selection in order to construct a good se-
quence for the respective class using an iterative compilation technique. The proposed
approach entirely bypasses these hurdles by starting with the optimization sequences
and then identifying the program classes they cover. In effect we completely reverse
the sequence selection technique using program classiﬁcation.

3.2. Intuition
We want to construct a set of sequences such that for every program class there exists
at least one good sequence in the set. We call this set as the good sequences set. If
the size of the good sequences set is small, then for a given program we can try all
the sequences in the set and choose the sequence which gives the best performance.
We avoid the program classiﬁcation problem by exhaustively trying all the sequences.
This technique will be effective if the good sequences set covers all the program classes
and will be practical only if the size of the good sequences set is small. So the crux of
the problem is to construct a tight but rich good sequences set.

We call the inﬁnite collection of programs as program space drawing an analogy from
vector spaces of linear algebra. We call the set of programs for which an optimization
sequence gives good performance as the hyperplane passing through the respective
programs in the program space and it is associated with the respective sequence. The
objective now is to select as few hyperplanes as possible so that the entire program
space is covered. The sequences corresponding to the chosen hyperplanes constitute
the good sequences set.

We can hypothetically envisage an algorithm wherein we choose a hyperplane which
covers maximum number of programs in the program space. Then we choose another
hyperplane which covers maximum number of programs not covered by the ﬁrst hy-
perplane. We keep iterating this step until the entire program space is covered. If we
assume that the program space is ﬁnite (which it is not) and if in each iteration a
hyperplane covers a constant fraction of the remaining programs, then the algorithm
converges in logarithmic steps yielding a small good sequences set.

We cannot implement the above algorithm unless we ﬁnd a way to handle the inﬁ-
nite size of the program space. This issue is addressed by choosing a ﬁnite collection of

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:7

benchmark programs which is representative of the program class distribution in the
program space. We choose the Microkernels benchmark suite as a representative sam-
ple of the program space. It has to be noted that how well the Microkernels benchmark
suite represents the actual program class distribution needs to be studied. Assuming
that the Microkernels benchmark suite approximates the actual program class dis-
tribution, we use that suite to downsample the inﬁnitely large optimization sequence
space to a small set of good sequences. This small set of good sequences covers all the
program classes. The size of this set turned out to be 290 in our experiments. However
exhaustively trying out all these sequences is not practical, so we reduce this sequence
set further down to 10 by using two techniques. We call the ﬁrst technique as the Best-
10 approach and the second technique as the Sequence Clustering approach. In the
next subsection we present the optimization space downsampling approach using the
Microkernels benchmark suite and in the later subsections we present the Best-10 and
Sequence Clustering algorithms.

3.3. Optimization Sequence Space Downsampling
Optimization sequence space consists of all optimization sequences and is a count-
able inﬁnite set. Corresponding to every program class we could think of a subspace
consisting of sequences which are good for that program class. We assume that all the
programs can be coarsely grouped into a small number of ﬁnite classes and hence there
are small number of good sequence subspaces catering to these program classes. If we
have a diverse collection of programs that cover all the program classes, then by ﬁnding
good sequences for each of these programs we get a optimization sequence set which
covers all the optimization sequence subspaces. This is crux of the our downsampling
technique.

As mentioned earlier we choose the Microkernels benchmark suite for optimization
sequence space downsampling. We used six different iterative compilation techniques
to construct good sequences corresponding to each of the Microkernel programs. Since
there are 61 Microkernel programs, a good sequence set of size 366 is generated. Due
to the redundancies in the good sequence set, the ﬁnal downsampled optimization se-
quence set size came down to 290. The following are the three iterative compilation
techniques used in the downsampling procedure.

(1) Genetic Algorithm with a Rank Selector: We used a genetic algorithm with the
following parametric choice: Chromosome size = 50, population size = 60, number
of generations = 100, mutation rate = 0.02, crossover rate = 0.9. If the standard
deviation of the ﬁtness score for a population is less than 0.01 or the best ﬁtness
score does not improve for 3 consecutive generations, the algorithm will terminate.
(2) Genetic Algorithm with a Tournament Selector: This version of the genetic
algorithm is exactly same as the above except that we used a Tournament Selector
instead of a Rank Selector.

(3) Uniform Random Search: In this algorithm, we generate 500 sequences of

length 50 each by uniform random sampling and pick the best sequence.

The other 3 iterative compilation techniques are exactly the same except that we
update an optimization sequence before it is applied on the LLVM IR. A quick look
at the LLVM manual [LLVM 2012] suggests what optimizations could precede and
succeed an optimization for its effectiveness. For example the manual suggests that
after -constprop (constant propagation) pass, it is a good idea to apply -die (dead in-
struction elimination) pass. So whenever -constprop pass appears in an optimization
sequence, we modify the sequence by inserting -die pass immediately after that. By
modifying the optimization sequences in this manner, we incorporate human knowl-
edge and experience in an iterative compilation technique, so that the algorithm can

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:8

Fig. 4. Program compilation setup with optimization sequence updates.

build upon it to converge to an optimal sequence faster. Figure 4 shows the modiﬁed
program compilation set.

While applying an iterative compilation technique there are optimization sequences
which crash the compiler. We simply ignore those sequences. It is also possible that
some of the sequences may generate incorrect code due to possible bugs in the compiler.
However we do not check for correctness in the downsampling phase. This is due to
lack of proper test suite infrastructure for the Microkernels benchmarks which could
be developed in due time. But the correctness of the sequences on the test programs
from the MiBench and PolyBench suites is veriﬁed.

Each of the sequences present in the downsampled optimization sequence set con-
tains optimizations not contributing to the program speed up or have a negative im-
pact on the program speed up due to false interactions with other optimizations. We
eliminate these unnecessary optimizations in a sequence by applying the Sequence Re-
duction Algorithm (see Algorithm 1). The Sequence Reduction algorithm keeps drop-
ping optimizations from a sequence as long as the runtime of the program does not
increase. The algorithm terminates when dropping any optimization from the remain-
ing sequence increases the program runtime. The length of the sequences in the down-
sampled optimization sequence set reduced by almost 80 percent after applying the
Sequence Reduction algorithm.

3.4. Best-10 Approach
After reducing the sequences in the downsampled sequence set, we construct a perfor-
mance summary matrix PM. The rows of the the matrix PM are labeled with the Micro-
kernel programs and the columns with the sequences from the downsampled sequence
set. If a row is labeled with a program p and a column with a sequence s, then the ma-
trix entry P M [p, s] contains the runtime of the program p when optimized using the
sequence s. We then apply a Sequence Extraction algorithm on the performance sum-
mary matrix to extract the Best-10 sequences covering the Microkernels benchmark
suite. The Sequence Extraction algorithm identiﬁes the sequence which improves the
performance of maximal number of Microkernel programs over -O2. In other words,
if we put a cross mark over the matrix entries which are strictly less than the corre-
sponding program’s -O2 runtime, then the algorithm picks a sequence corresponding
to a column with maximal number of cross marks. Ties are resolved by picking the se-
quence which gives maximum average speedup. This sequence is included in the good
sequences set and the corresponding column will be eliminated from the matrix. The
rows corresponding to the programs which got covered by this sequence will also be
eliminated. Now the same procedure is applied on the reduced matrix until either the
rows of the matrix are completely exhausted or a predetermined bound on the good
sequences set size is reached. The construction of the good sequences set is a one time
ofﬂine procedure. After that given a new program we can try all the sequences from

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:9

ALGORITHM 1: Sequence Reduction Algorithm

Input: Program and an optimization sequence
Output: Reduced optimization sequence
bestseq ← optseq ;
besttime ← program runtime using bestseq ;
change ← True ;
while change = True do

change ← False;
bestseqlen ← length of bestseq ;
for i=1 to bestseqlen do

currseq ← bestseq - { ith optimization of bestseq} ;
currseqtime ← program runtime using currseq ;
if currseqtime ≤ besttime then

besttime ← currseqtime ;
bestseq ← currseq ;
change ← True ;
break from the for loop ;

end

end

end
return bestseq ;

/* return the reduced sequence */

the good sequences set and choose the sequence which gives the best speedup. Refer
Algorithm 2 for the Sequence Extraction algorithm pseudocode.

3.4.1. Best-12 – A Modiﬁed Best-10 Approach. Best-12 is a variant of the Best-10 tech-
nique. In this approach, we apply the Best-10 algorithm and out of the ten extracted
sequences we pick the top six sequences. Then we remove these six sequences from the
downsampled sequence set and repeat the Best-10 algorithm on the rest of the down-
sampled sequence set. Out of the new best ten sequences we pick the top six sequences
again. The top six sequences from the two phases put together gives the Best-12 se-
quences. This approach uncovers the good sequences in the second application of Best-
10 algorithm that are eliminated by the top sequences during the ﬁrst application of
Best-10 algorithm. This approach which is slightly counter intuitive can be partially
explained by saying that it is better to have more optimization sequence samples from
dominant program classes than to have optimization sequences corresponding to small
program classes.

3.5. Sequence Clustering Approach
The downsampled optimization sequence set is a union of optimization sequence sub-
spaces corresponding to various program classes. If we can identify these optimization
sequence subspaces, then we can pick representative sequences from each of the sub-
spaces to construct the ﬁnal reduced set of good sequences. In this section we propose
a sequence clustering algorithm to identify the optimization sequence subspaces and
a way to pick representative sequences from each of the subspaces.

Let m be the number of programs in the Microkernels benchmark suite. Correspond-
ing to a sequence s we deﬁne a sequence vector Vs such that the ith entry in the vector
Vs is 1 if the sequence s improves the performance (over -O2) of the ith program in
the Microkernel benchmark suite. Otherwise the ith entry is equal to 0. We construct
a sequence similarity matrix SS such that the rows and the columns of the matrix
are labeled with the sequences from the downsampled optimization set. If p and q are
two sequences, then the matrix entry SS[p, q] contains the Euclidean distance between

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:10

ALGORITHM 2: Best-10 Sequence Extraction Algorithm

Input: List of 290 sequences, list of Microkernel programs, performance summary matrix (PM).
Output: Best-10 sequences.
seq290 ← List of all 290 sequences ;
prgms ← List of all Microkernel programs ;
for each seq in seq290 do

for each prgm in prgms do

if PM[prgm, seq] < clang -O2 runtime of prgm then

Dict[seq].append([prgm, speedupoverO2]) ;

end

end

end
Best10 ← { } ;
for i = 1 to 10 do

/* Pick the sequence for which the length of the list Dict[s] is maximum. If

there are ties, pick the one with maximum total speedup among the tied
sequences.

S = getmaximum(Dict) ;
Best10.append(S) ;
/* Delete all programs that are covered by S
for seq in Dict.keys() do

for prgm in Dict[S] do

if prgm ∈ Dict[seq] then

Dict[seq].delete(prgm) ;

end

end

end

end

*/

*/

the vectors Vp and Vq. We then apply the Sequence Clustering algorithm (Refer Algo-
rithm 3) to partition the downsampled sequence space into 10 clusters. The sequence
clustering algorithm is minor variant of the standard k-means clustering algorithm.
The algorithm starts with randomly initializing 10 sequence vectors as the cluster cen-
ters. The rest of the sequence vectors are assigned to the closest cluster center. Now
the mean vector for each cluster is computed. This mean vector will not correspond to
any of the sequence vectors usually. So the closest sequence vector to the mean vector
is made cluster center in the next iteration. This process repeats until the clusters con-
verge or a predeﬁned number of iterations are reached. It has to be noted that because
of the way we shift the cluster center, the algorithm may not converge like the usual
k-means algorithm.

After the sequence clusters are constructed, we pick an arbitrary cluster and from
that cluster pick a sequence which covers maximum number of Microkernel bench-
mark programs when compared to the rest of the sequences in the cluster. Note that
the sequence selected using this approach may not be the cluster centroid. We then
remove the set of programs covered from the Microkernels suite and repeat the same
process by choosing yet another cluster arbitrarily until all clusters are exhausted.
The ten sequences thus selected are not deterministic as the initial cluster centers
in the cluster selection algorithm are chosen at random. The quality of the clusters
constructed and hence the quality of the ﬁnal selected sequences depends on the ini-
tial choice of cluster centers. So we ran the Sequence Clustering algorithm 100 times
and computed the corresponding sequence sets each of size 10 sequences. Then among
those hundred sequence sets we pick the sequence set which covered the maximum

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:11

/* List of cluster centers */

ALGORITHM 3: Sequence Clustering Algorithm

Input: Sequence Similarly Matrix (SS).
Output: Ten clusters.
seq290 ← List of all 290 sequences ;
prgms ← List of all Microkernel programs ;
Pick 10 sequences s1, · · · , s10 uniformly at random. ;
centroid = [s1, · · · , s10] ;
oldcentroid = [−1, · · · , −1] ;
while oldcentroid != centroid do

oldcentroid = centroid ;
for each s in seq290 do

min = -1 ;
for j in centroid do

if min > SS[s][j] then

min = SS[s][j] ;
clr = j ;

end
clusters[clr].append(s)

end

end
for each cluster in clusters do

mean = mean of all the sequence vectors in this cluster;
center = the point in the cluster that is closest to mean ;
update centroid[i] to center ;

end

end

number of Microkernel programs. It is important to note that we did not use the test
benchmark programs to select the ﬁnal set of 10 sequences.

4. EXPERIMENTAL RESULTS
As discussed earlier we used the LLVM compiler infrastructure to test the proposed
approach. Microkernels benchmark suite is used to construct the good sequences set
and the resulting good sequences are tested on the MiBench [Guthaus et al. 2001] and
Polybench 3.0 programs. We used the data set one for the MiBench programs and the
large data set for the PolyBench programs. All the experiments are carried out on an
Intel Xeon Processor W3550 machine with 12GB RAM and Linux operating system
running on it. The work load on the system is kept to bare minimum to reduce the
variance in measured program runtimes. We also checked the variance in the program
runtimes by running the programs for multiple times and found the variance to be
negligible. The performance of the good sequences is compared with the LLVM -O2
option instead of -O3 as it is giving better performance than -O3 on most programs.

4.1. Sequence Analysis
Table II gives the optimization sequence corresponding to -O2. Tables III, IV and V
gives the good sequence sets obtained by using the Best-10, Best-12 and Cluster-10
approaches respectively. These tables also give the optimizations not occurring in any
of the the sequences in the good sequences set. Table VI gives the frequency with
which various optimizations occurred in the All-290 and Best-10 sequence sets. The
frequency tables corresponding to Best-12 and Cluster-10 sequences look similar. Ta-
ble VI statistically explains why certain optimizations are not ﬁguring in any of the
good sequences. However to give a qualitative reasoning requires an understanding

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:12

Table II. LLVM -O2 Sequence

-basiccg,

-inline,

-prune-eh,

[-targetlibinfo, -targetdata, -no-aa, -tbaa, -basicaa, -globalopt, -ipsccp, -deadargelim, -instcombine,
-simplifycfg,
-early-
cse, -simplify-libcalls, -lazy-value-info, -jump-threading, -correlated-propagation, -simplifycfg, -
instcombine, -tailcallelim, -simplifycfg, -reassociate, -domtree, -loops, -loop-simplify, -lcssa, -
loop-rotate, -licm, -lcssa, -loop-unswitch, -instcombine, -scalar-evolution, -loop-simplify, -lcssa, -
indvars, -loop-idiom, -loop-deletion, -loop-unroll, -memdep, -gvn, -memdep, -memcpyopt, -sccp, -
instcombine, -lazy-value-info, -jump-threading, -correlated-propagation, -domtree, -memdep, -dse,
-adce, -simplifycfg, -instcombine, -strip-dead-prototypes, -constmerge, -preverify, -domtree, -verify]

-scalarrepl-ssa,

-functionattrs,

-domtree,

Table III. Best-10 Sequences and their respective lengths.

S. No

Best-10 Sequences

Length

1

2

3

4

5

6

7

8

9

[-instcombine, -simplifycfg, -gvn, -indvars, -loop-rotate, -unroll-allow-partial,
-loop-unroll,
-loop-rotate,
-
reassociate, -instcombine]

-gvn, -inline, -early-cse,

-loop-unroll,

-basicaa,

[-simplify-libcalls,
-
instcombine, -inline, -globalopt, -scalarrepl, -loop-rotate, -loop-unroll, -loop-
instsimplify]

-unroll-allow-partial,

-simplifycfg,

-internalize,

-gvn,

[-gvn, -loop-rotate, -internalize, -inline, -licm, -tailcallelim, -instcombine, -
basicaa, -indvars]

[-codegenprepare, -loop-rotate, -loop-idiom, -loop-deletion, -gvn]

[-loop-rotate, -inline, -simplify-libcalls, -basicaa, -licm, -constmerge, -indvars,
-unroll-allow-partial, -loop-unroll, -reassociate, -gvn]

[-simplifycfg, -tailcallelim, -early-cse, -loop-rotate, -internalize, -partial-inliner,
-instcombine, -inline, -ipsccp]

[-internalize, -inline, -globalopt, -early-cse, -licm, -basicaa, -indvars, -loop-
reduce]

[-codegenprepare,
rotate, -indvars, -reassociate]

-gvn,

-tailcallelim,

-reassociate,

-basicaa,

-inline,

-loop-

[-simplifycfg, -tailcallelim, -instcombine, -early-cse]

10

[-early-cse, -simplifycfg, -gvn, -inline, -loop-reduce, -licm, -instcombine, -gvn,
-reassociate]

Optimizations not ﬁguring in any of the Best-10 Sequences

15

12

9

5

11

9

8

9

4

9

-adce, -always-inline, -argpromotion, -constprop, -correlated-propagation, -dce, -deadargelim, -die,
-dse, -globaldce, -instsimplify, -ipconstprop, -jump-threading, -loop-simplify, -loop-unswitch, -loops,
-lower-expect, -loweratomic, -lowerinvoke, -lowerswitch, -memcpyopt, -mergefunc, -mergereturn,
-prune-eh, -sccp, -sink, -targetlibinfo, -no-aa, -tbaa, -basiccg, -functionattrs, -scalarrepl-ssa, -
domtree, -lazy-value-info, -lcssa, -scalar-evolution, -memdep, -strip-dead-prototypes

of the optimizations, their implementation in the compiler and for what kind of pro-
grams those optimizations are targeted. For example -prune-eh optimization may be
valid only for C++ programs whereas all the Microkernel benchmark programs are C
programs.

4.2. Performance Analysis
Program speedup and percentage improvement are calculated as follows:

Speedup = O2runtime
newruntime

P ercentage Improvement = (Speedup − 1) ∗ 100

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Table IV. Best-12 Sequences and their respective lengths.

S. No

Best12 Sequences

Length

39:13

1

2

3

4

5

6

7

8

9

10

11

12

[-instcombine, -simplifycfg, -gvn, -indvars, -loop-rotate, -unroll-allow-partial,
-loop-unroll,
-
-loop-rotate,
reassociate, -instcombine]

-gvn, -inline, -early-cse,

-loop-unroll,

-basicaa,

[-simplify-libcalls,
-
instcombine, -inline, -globalopt, -scalarrepl, -loop-rotate, -loop-unroll, -loop-
instsimplify]

-unroll-allow-partial,

-simplifycfg,

-internalize,

-gvn,

[-gvn, -loop-rotate, -internalize, -inline, -licm, -tailcallelim, -instcombine, -
basicaa, -indvars]

[-codegenprepare, -loop-rotate, -loop-idiom, -loop-deletion, -gvn]

[-loop-rotate, -inline, -simplify-libcalls, -basicaa, -licm, -constmerge, -indvars,
-unroll-allow-partial, -loop-unroll, -reassociate, -gvn]

[-simplifycfg, -tailcallelim, -early-cse, -loop-rotate, -internalize, -partial-inliner,
-instcombine, -inline, -ipsccp]

[-internalize, -inline, -globalopt, -early-cse, -licm, -basicaa, -indvars, -loop-
reduce]

[-loop-rotate, -internalize, -instcombine, -globalopt, -gvn, -inline, -simplifycfg,
-scalarrepl-ssa, -loop-deletion, -inline, -adce, -loop-unroll, -globalopt, -basicaa,
-licm]

[-codegenprepare, -instcombine, -loop-rotate, -loop-idiom, -loop-deletion, -gvn,
-sink]

[-loop-reduce, -inline, -loop-unroll, -indvars, -loop-rotate, -simplify-libcalls, -
early-cse]

[-inline, -loop-rotate, -basicaa, -gvn, -loop-unroll, -simplify-libcalls, -licm]

[-instcombine, -simplifycfg]

Optimizations not ﬁguring in any of the Best-12 Sequences

15

12

9

5

11

9

8

15

7

7

7

2

-always-inline, -argpromotion, -constprop, -correlated-propagation, -dce, -deadargelim, -die, -dse,
-globaldce, -instsimplify, -ipconstprop, -jump-threading, -loop-simplify, -loop-unswitch, -loops, -
lower-expect, -loweratomic, -lowerinvoke, -lowerswitch, -memcpyopt, -mergefunc, -mergereturn,
-prune-eh, -sccp, -targetlibinfo, -no-aa, -tbaa, -basiccg, -functionattrs, -domtree, -lazy-value-info,
-lcssa, -scalar-evolution, -memdep, -strip-dead-prototypes.

Tables VII and VIII give the speedup of the MiBench and PolyBench programs us-
ing Genetic, All290, Best-10, Best-12 and Cluster-10 approaches8. Genetic algorithm
being an iterative compilation technique applied on a per program basis gives an ap-
proximate upper bound on the achievable speedup. The column labeled All290 gives
the speedup using all the sequences in the downsampled sequence set. All290 column
gives the maximum speedup possible for any sequence extraction algorithm using the
downsampled sequence set. The speedup due to All290 does not indicate the best pos-
sible speedup achievable as we could be missing the optimal sequence for a program
completely from the downsampled sequence set. However our experimental results
show that All290 is performing on par with the genetic algorithm and in some cases
even doing better than genetic. We can say that the downsampled sequence set con-
tains rich and diverse sequences from this observation.

The MiBench suite consists of 17 unique programs. Some programs like
automotive susan call different functions based on the command line option being
passed to the program. For example the options -e, -c and -s respectively invoke the

8Due to space constraints we are not able to represent all the data graphically. However bar graphs compar-
ing the performance of Cluster-10 approach with All290 which is doing better than genetic are provided.

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:14

Table V. Cluster-10 Sequences and their respective lengths.

S. No

Cluster-10 Sequences

Length

1

2

3

4

5

6

7

8

9

[-inline,
threading, -gvn, -licm]

-basicaa,

-loop-rotate,

-unroll-allow-partial,

-loop-unroll,

-jump-

[-loop-rotate, -internalize, -instcombine, -globalopt, -gvn, -inline, -simplifycfg,
-scalarrepl-ssa, -loop-deletion, -inline, -adce, -loop-unroll, -globalopt, -basicaa,
-licm]

[-early-cse, -simplifycfg, -tailcallelim, -reassociate, -lowerswitch, -reassociate]

[-instcombine, -loop-rotate, -inline, -simplify-libcalls, -basicaa, -functionattrs,
-loop-unswitch, -indvars, -loop-unroll, -gvn]

-indvars,
[-instcombine,
reassociate,
-ipconstprop,
allow-partial, -loop-unroll]

-simplify-libcalls,
-instcombine,

-reassociate,

-loop-rotate,

-internalize,

-simplifycfg,

-
-unroll-

[-internalize, -inline, -globalopt, -early-cse, -licm, -basicaa, -indvars, -loop-
reduce]

[-simplifycfg, -inline, -internalize, -instcombine, -simplify-libcalls, -indvars, -
inline, -loop-reduce, -ipsccp, -licm, -simplifycfg]

[-codegenprepare, -instcombine, -loop-rotate, -loop-idiom, -loop-deletion, -gvn,
-sink]

[-simplifycfg, -tailcallelim, -jump-threading, -loop-rotate]

10

[-simplifycfg, -tailcallelim, -instcombine, -early-cse]

Optimizations not ﬁguring in any of the Cluster-10 Sequences

8

15

6

10

12

8

11

7

4

4

-argpromotion,

-
-always-inline,
deadargelim,
-
lower-expect, -loweratomic, -lowerinvoke, -memcpyopt, -mergefunc, -mergereturn, -partial-inliner,
-prune-eh, -scalarrepl, -sccp, -targetlibinfo, -no-aa, -tbaa, -basiccg, -domtree, -lazy-value-info,
-lcssa, -scalar-evolution, -memdep, -strip-dead-prototypes

-correlated-propagation,
-loop-simplify,

-loop-instsimplify,

-dce,
-loops,

-constmerge,

-die,

-dse,

-globaldce,

-instsimplify,

-constprop,

functions susan edges, susan corners and susan smoothing. The program pretty much
spends all the time in one of these functions. The program versions as deﬁned by the
command line options are called uniquely as automotive susan e, automotive susan c
and automotive susan s respectively. Each of these program versions may have a
different optimal optimization sequence. Whereas the Table VII shows the speedup
of the programs by treating each of the program versions as unique programs, Fig-
ure 5 shows the speedup of the programs by averaging the speedup of different pro-
gram versions. The ﬁnal average speedup shown in the graph is the average of av-
erages. A maximum improvement of around 38 percent has been obtained for the
programs automotive susan s and security sha. Cluster-10 sequences are only able
to give 23 percent improvement for security sha. There is a minor loss in perfor-
mance for the programs network patricia and consumer tiffmedian. For these pro-
grams there are no good sequences in the downsampled sequence set. For the pro-
gram office stringsearch1, the sequence [-functionattrs, -loop-rotate, -licm,
-basicaa] in the All290 sequences optimizes it to run in 0.1 seconds as against the -O2
runtime of 3.1 seconds. However this sequence does not ﬁgure out in any of the Best-
10, Best-12 and Cluster-10 sequence sets. The order in which the four optimizations
occur in the aforementioned sequence is so important that any changes to it increases
the runtime to 3 seconds. Further the optimization -functionattrs occurs only in 13 of
the 290 sequences. It is not clear whether we will be able to predict such sequences us-
ing machine learning based prediction models. Also due to this program All290 shows
a higher average improvement when compared with other approaches.

Table VIII gives the speedup of the PolyBench programs using Genetic, All290, Best-
10, Best-12, Cluster-10 sequences. Figures 6 and 7 shows the performance comparison

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Table VI. Frequency with which various optimizations occurred in All-290 and Best-10 sequence sets.

Optimizations

All-290

Best-10

Optimizations

All-290

Best-10

39:15

-loop-rotate

-inline

-indvars

-gvn

-instcombine

-basicaa

-licm

-internalize

-simplifycfg

-early-cse

-jump-threading

-simplify-libcalls

-reassociate

-globalopt

-loop-unroll

-loop-reduce

-tailcallelim

-loop-deletion

-ipsccp

-codegenprepare

-loop-idiom

-partial-inliner

-scalarrepl

-scalarrepl-ssa

-sink

-functionattrs

-loop-unswitch

-deadargelim

-sccp

-correlated-
propagation

-dse

193

154

151

136

122

114

102

98

72

61

60

56

55

54

51

45

38

29

24

17

17

15

15

15

14

13

12

12

11

11

11

8

8

5

9

7

5

4

4

5

5

0

2

5

2

4

2

4

1

1

2

1

1

1

0

0

0

0

0

0

0

0

-globaldce

-adce

-ipconstprop

-lowerswitch

-constmerge

-argpromotion

-loop-instsimplify

-lcssa

-basiccg

-dce

-strip-dead-prototypes

-instsimplify

-always-inline

-memcpyopt

-tbaa

-loop-simplify

-mergereturn

-lower-expect

-memdep

-lazy-value-info

-die

-constprop

-targetlibinfo

-mergefunc

-prune-eh

-scalar-evolution

-no-aa

-lowerinvoke

-loops

-loweratomic

-domtree

10

10

8

7

7

5

4

4

3

3

3

2

2

1

1

1

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

1

0

1

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

using Cluster-10 and All-290 sequences. The speed up for all the programs (except for
reg detect) approaches All290. Ten out of thirty programs show at least 15 percent
improvement. The rest of the programs show minor or no improvement at all. However
in all the cases the performance of the proposed approaches is almost the same as that
of genetic. A maximum speedup of 75 percent is obtained for the program dynprog.

4.3. False Interactions between Optimizations in the LLVM -O2 Sequence
We applied the Sequence Reduction Algorithm 1 on the -O2 sequence while optimiz-
ing the Microkernels programs in order to understand the impact of the optimizations
on the program runtime and interactions between them. Table IX shows the -O2 run-
times for the Microkernels program and the runtimes after the sequence reduction.
The maximum sequence length after reduction is 10 which is substantially small when

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:16

Fig. 5. Performance comparison of the Cluster10 approach with All290 on MiBench programs.

compared to the original -O2 sequence length of 62. Further 16 out of 61 Microkernel
programs show at least 10 percent improvement over their original -O2 runtimes and
8 out of those 16 programs show at least 20 percent improvement.

5. RELATED WORK
Touati and Barthou [Touati and Barthou 2006] showed that the phase ordering prob-
lem in its full generality is undecidable. They also showed that given an optimiza-
tion sequence consisting of parametric optimizations, ﬁnding the optimal parameters
for individual optimizations is also an undecidable problem. They proposed decidable
variants for both these problems. Kulkarni et al. [Kulkarni et al. 2006] proposed an
exhaustive search strategy to ﬁnd optimal compilation sequences for each of the func-
tions in a program. Multiple optimization sequences can lead to the same target code.
They use this idea to prevent the combinatorial explosion of the total number of se-
quences to be tested. Although this approach gives interesting information about op-
timization sequence space like number of local minima etc., it may not be a practical
approach. Pan and Eigenmann [Pan and Eigenmann 2006] proposed a search algo-
rithm called combined elimination which eliminates weakly interacting optimizations
having a negative impact on the program in a single iteration. This allows the al-
gorithm converge to a near optimal solution fast. Cooper, Subramanian and Torczon
[Cooper et al. 2002] performed experiments to characterize the optimization sequence

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:17

Fig. 6. Performance comparison of the Cluster10 approach with All290 on PolyBench programs.

space and suggested that the optimal solutions are rare with frequent local minima in
the space. So simple hill-climbing search strategies may not work. However the char-
acteristics of the optimization state space could vary a lot from compiler to compiler.
Cooper, Schielke and Subramanian [Cooper et al. 1999] used a genetic algorithm based
approach to ﬁnd optimization sequences which reduce code size. Generating executa-
bles with small memory footprint is important while compiling embedded applications
to be ported on devices with small ﬂash memory. Triantafyllis et al. [Triantafyllis et al.
2003] proposed an iterative compilation technique which factors in compiler writer’s
knowledge to reduce the search space. Further the search is performed only on the hot
code segments. The search time in iterative compilation techniques could be reduced
by using performance estimators as proposed in [Cooper et al. 2005] by Cooper et al.
Agakov et al. [Agakov et al. 2006] proposed a biased search technique using Markov
models to reduce the number of iterations required to converge to a near optimal se-
quence. The Markov model used to bias the search space is learnt off-line using a set
of training programs.

As discussed earlier for the effectiveness of a machine learning technique, the choice
of relevant features is vital. Leather et al. [Leather et al. 2009] proposed an automatic
feature generation technique which uses genetic programming. Cavazos et al. [Cava-
zos et al. 2007] proposed a machine learning model using hardware performance coun-
ters as program features. They used logistic regression model to predict the probability
with which an optimization should be enabled. Once the probability prediction models

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:18

Fig. 7. Performance comparison of the Cluster10 approach with All290 on PolyBench programs.

for various optimizations are learnt, a biased search of the sample space is performed.
Fursin et al. ([Fursin et al. 2011], [Fursin and Temam 2010]) proposed a probabilistic
prediction model and they used static program features to represent a program. Park
et al. [Park et al. 2011] proposed a sequence prediction model using tournament pre-
dictors whereas Thomson et al. [Thomson et al. 2009] proposed a nearest-cluster based
approach. Cavazos et al. [Cavazos et al. 2006] proposed an approach for performance
prediction when a particular program transformation is applied without actually run-
ning the programs. This approach can be used in the optimization sequence selection
problem to reduce the number of program evaluations either in the iterative compila-
tion or in the machine learning based techniques.

Machine learning based prediction models have been used in other parameter es-
timation problems like loop unrolling [Stephenson and Amarasinghe 2005]. Kisuki
et al. [Kisuki et al. 2000] tried to attack a similar problem using iterative compila-
tion techniques. Wang and Boyle [Wang and O’Boyle 2009] proposed a machine learn-
ing technique to predict an optimal scheduling policy for programs parallelized using
openmp. There are many research efforts in applying predictive modelling techniques
in adaptive virtual machines ([Arnold et al. 2005], [Cavazos and O’Boyle 2006], [Gu
and Verbrugge 2008]).

6. CONCLUSIONS AND FUTURE WORK
In this paper we proposed a practical approach to solve the optimization phase order-
ing problem. This approach is quite different from the iterative compilation and ma-
chine learning based prediction techniques. The idea is to downsample the inﬁnitely
large optimization sequence space using a benchmark suite representative of the pro-
gram class distribution in the program. Then the downsampled sequence set can be
further reduced to a very small set of good sequences such that it covers all program
classes. Then given new program we can try all the sequences from the good sequences
set and choose the best sequence. There is no need to identify a program class during

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Table VII. Speed up obtained on the MiBench programs using Genetic, All290, Best-
10, Best-12 and Cluster-10 sequences. API stands for average percentage improve-
ment, APIE stands for average percentage improvement excluding the programs
showing no speed up and NPS stands for the number of programs achieving speedup.

Program

Genetic

All290

Best-10

Best-12

Cluster-10

39:19

telecom CRC32

automotive qsort1

telecom adpcm c

automotive susan e

automotive susan c

telecom adpcm d

consumer tiff2rgba

security rijndael d

security rijndael e

automotive susan s

ofﬁce stringsearch1

consumer lame

consumer tiffdither

network dijkstra

telecom gsm

automotive bitcount

bzip2e

bzip2d

network patricia

consumer tiffmedian

security sha

consumer jpeg d

consumer jpeg c

consumer tiff2bw

security blowﬁsh e

security blowﬁsh d

1.01

1.01

1.17

1.16

1.2

1.27

1.22

1.03

1.04

1.23

1

1.01

1.12

1.03

1.17

1.14

1.15

1

0.98

1.06

1.51

1.02

1.1

1.22

1.01

1.05

1.01

1.03

1.16

1.32

1.32

1.25

1.2

1.02

1.03

1.4

2

1.01

1.09

1.11

1.17

1.11

1.14

1.16

0.99

1.02

1.39

1.01

1.11

1.14

1.05

1.09

1.01

1.02

1.15

1.3

1.27

1.23

1.11

1.03

1.03

1.37

0.83

0.97

1.07

1.03

1.15

1.02

1.11

1.01

0.95

0.94

1.38

1.01

1.04

1.1

1.05

1.09

API

APIE

NPS

Performance Results Summary

11.2

12.7

23

16.7

17.4

25

8.73

11.7

22

1.01

1.03

1.02

1.3

1.27

1.23

1.13

1.02

1.03

1.38

0.83

1.01

1.08

1.05

1.15

1.06

1.1

1.16

0.96

1

1.39

1

1.07

1.1

1.05

1.09

9.7

12.4

22

1.01

1.02

1.16

1.32

1.3

1.19

1.15

1.01

1

1.38

0.99

1.01

1.06

1.05

1.14

1.06

1.1

1.14

0.95

0.9

1.23

1.01

1.11

1.12

1.05

1.09

9.8

12.3

22

this process. The following are few interesting problems which are due to the proposed
technique:

(1) The effectiveness of the proposed approach depends on the diversity of the Mi-
crokernels benchmark suite. So program diversity analysis of the Microkernels
benchmark suite has to be done and thereby enrich it with new programs.

(2) The quality of the downsampled sequence set depends on the iterative compilation
techniques applied on the Mircokernels benchmark suite. Better iterative compi-
lation techniques lead to higher quality sequences in the downsampled set.

(3) We can possibly reverse engineer our approach to solve the program classiﬁcation
problem by ﬁnding correlations between the class labels given by optimization se-
quences to the programs and their static/dynamic features.

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:20

Table VIII. Speed up obtained on the PolyBench programs using Genetic, All290,
Best-10, Best-12 and Cluster-10 sequences. API stands for average percentage
improvement, APIE stands for average percentage improvement excluding the
programs showing no speed up and NPS stands for the number of programs
achieving speedup.

Program

Genetic

All290

Best-10

Best-12

Cluster-10

bicg

syrk

jacobi-1d-imper

trmm

syr2k

cholesky

fdtd-apml

3mm

lu

doitgen

seidel-2d

gemm

adi

gesummv

ﬂoyd-warshall

ludcmp

covariance

symm

atax

jacobi-2d-imper

trisolv

2mm

mvt

gemver

fdtd-2d

reg detect

correlation

gramschmidt

dynprog

durbin

1.22

1.06

1

1.05

0.84

1.02

1.01

1

1

1.04

1.02

1

0.97

1.22

0.97

1.01

1

1.04

1.28

1.24

1.32

0.99

1.21

1.16

1.12

1.2

1

1

1.82

1.22

1.3

1.08

1.05

1.05

1.02

1.02

1.03

1.02

1

1.07

1.01

1.02

1.01

1.26

1.03

1.03

1.02

1.05

1.38

1.27

1.44

1.02

1.29

1.26

1.15

1.2

1.01

1.02

1.86

1.2

1.23

1.08

1

1

1.02

1.01

1.03

1.02

0.99

1.03

1

1.01

1

1.26

0.99

1.01

1.01

1.03

1.38

1.21

1.38

1.01

1.29

1.24

1.12

0.86

1

1.02

1.74

1.2

1.28

1.08

1

1

1.01

1.01

1.01

1.01

1

1.02

1

1.01

1.01

1.26

1

1.02

1.02

1.04

1.38

1.24

1.35

1.01

1.29

1.24

1.15

0.86

1.01

1.01

1.75

1.2

1.3

1.07

1

1.01

1.01

1.01

1.01

1.01

1

1.02

1

1.01

1.01

1.26

1

1.02

1.02

1.04

1.3

1.27

1.35

1.01

1.26

1.24

1.15

0.86

1.01

1.01

1.75

1.2

Performance Results Summary

API

APIE

NPS

10.87

17.15

19

13.9

14.37

29

11.1

14.5

23

11.37

14.2

24

11.17

13.4

25

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Table IX. Comparison of runtimes for -O2 and reduced -O2 sequences

39:21

Program
ﬂops-7.c
queens.c

whetstone.c

lists.c

n-body.c
ﬂops-2.c

ReedSolomon.c

ﬂops-3.c
ﬂops-6.c
ﬂops-5.c
perm.c

recursive.c

fbench.c
ﬂops.c

richards benchmark.c

perlin.c
ﬂops-4.c
ary3.c

partialsums.c

lowercase.c
realmm.c

ﬁb2.c

mandel-2.c
quicksort.c

hash.c

nsieve-bits.c

oscar.c
intmm.c
ﬂops-1.c

ackermann.c

matrix.c
puzzle.c

queens-mcgill.c

ﬂdry.c

fannkuch.c

strcat.c
chomp.c

misr.c

mandel.c
heapsort.c
salsa20.c

puzzle-stanford.c

lpbench.c
oourafft.c
ﬂops-8.c

huffbench.c

pi.c

bubblesort.c

treesort.c
towers.c
random.c

fp-convert.c

dry.c

spectral-norm.c

methcall.c

sieve.c

nestedloop.c

himenobmtxpa.c

objinst.c
ffbench.c

dt.c

O2 time O2-reduced time O2-reduced length

3.29
1.81
1.18
5.36
1.05
1.21
4.88
1.59
1.23
1.3
3.23
0.92
1.51
7.55
0.77
4.42
0.77
1.58
0.52
5.95
2.32
2.38
1.03
3.19
3.18
4.08
1.96
1.56
2.05
1.2
2.49
0.49
1.83
1.74
2.08
1.31
1.61
0.17
0.83
2.12
6.8
2.91
4.06
4.08
1.37
4.91
0.51
3.81
6.78
2.35
2.66
2.6
1.75
1.1
3.44
5.23
0.2
0.79
3.66
0.65
1.76

3.28
1.77
1.16
4.44
1.02
1.16
4.64
1.56
1.2
1.3
2.64
0.72
1.54
7.49
0.69
3.9
0.74
1.53
0.52
5.79
2.3
2.29
0.96
2.99
3.18
3.45
1.86
1.56
2.05
0.87
2.29
0.04
1.75
1.68
2.1
1.19
1.51
0.16
0.82
2.08
6.18
2.88
4.03

4

1.34
4.12
0.51
3.55
6.73
2.09
2.67
2.3
0.47
1.1
3.29
5.2
0
1.6
0

0.65
1.76

4
7
10
3
0
3
7
6
5
8
2
3
8
6
8
7
0
6
0
4
7
4
6
8
7
0
7
5
1
3
7
3
7
10
4
0
1
4
3
4
7
9
9
9
1
16
7
5
9
5
4
2
13
0
1
6
2
12
8
2
2

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:22

REFERENCES

AGAKOV, F., BONILLA, E., CAVAZOS, J., FRANKE, B., FURSIN, G., O’BOYLE, M. F. P., THOMSON, J., TOU-
SSAINT, M., AND WILLIAMS, C. K. I. 2006. Using machine learning to focus iterative optimization. In
Proceedings of the International Symposium on Code Generation and Optimization. CGO ’06.

ARNOLD, M., FINK, S., GROVE, D., HIND, M., AND SWEENEY, P. 2005. A survey of adaptive optimization

in virtual machines. Proceedings of the IEEE 93, 2, 449 –466.

CAVAZOS, J., DUBACH, C., AGAKOV, F., BONILLA, E., O’BOYLE, M. F. P., FURSIN, G., AND TEMAM, O.
2006. Automatic performance model construction for the fast software exploration of new hardware
designs. In Proceedings of the 2006 international conference on Compilers, architecture and synthesis for
embedded systems. CASES ’06. ACM, New York, NY, USA, 24–34.

CAVAZOS, J., FURSIN, G., AGAKOV, F., BONILLA, E., O’BOYLE, M. F. P., AND TEMAM, O. 2007. Rapidly
selecting good compiler optimizations using performance counters. In Proceedings of the International
Symposium on Code Generation and Optimization. CGO ’07. IEEE Computer Society, Washington, DC,
USA, 185–197.

CAVAZOS, J. AND O’BOYLE, M. F. P. 2006. Method-speciﬁc dynamic compilation using logistic regression.

SIGPLAN Not. 41, 229–240.

CHEN, Y., HUANG, Y., EECKHOUT, L., FURSIN, G., PENG, L., TEMAM, O., AND WU, C. 2010. Evaluating
iterative optimization across 1000 datasets. In Proceedings of the 2010 ACM SIGPLAN conference on
Programming language design and implementation. PLDI ’10. ACM, New York, NY, USA, 448–459.

COOPER, K. D., GROSUL, A., HARVEY, T. J., REEVES, S., SUBRAMANIAN, D., TORCZON, L., AND WA-
TERMAN, T. 2005. Acme: adaptive compilation made efﬁcient. In Proceedings of the 2005 ACM SIG-
PLAN/SIGBED conference on Languages, compilers, and tools for embedded systems. LCTES ’05.

COOPER, K. D., SCHIELKE, P. J., AND SUBRAMANIAN, D. 1999. Optimizing for reduced code space using

genetic algorithms. SIGPLAN Not. 34, 1–9.

COOPER, K. D., SUBRAMANIAN, D., AND TORCZON, L. 2002. Adaptive optimizing compilers for the 21st

century. J. Supercomput. 23, 7–22.

FURSIN, G., KASHNIKOV, Y., MEMON, A. W., CHAMSKI, Z., TEMAM, O., NAMOLARU, M., YOM-TOV, E.,
MENDELSON, B., ZAKS, A., COURTOIS, E., BODIN, F., BARNARD, P., ASHTON, E., BONILLA, E. V.,
THOMSON, J., WILLIAMS, C. K. I., AND O’BOYLE, M. F. P. 2011. Milepost gcc: Machine learning en-
abled self-tuning compiler. International Journal of Parallel Programming 39, 3, 296–327.

FURSIN, G. AND TEMAM, O. 2010. Collective optimization: A practical collaborative approach. ACM Trans.

Archit. Code Optim. 7, 4, 20:1–20:29.

GU, D. AND VERBRUGGE, C. 2008. Phase-based adaptive recompilation in a jvm. In Proceedings of the 6th

annual IEEE/ACM international symposium on Code generation and optimization. CGO ’08. 24–34.

GUTHAUS, M. R., RINGENBERG, J. S., ERNST, D., AUSTIN, T. M., MUDGE, T., AND BROWN, R. B. 2001.
Mibench: A free, commercially representative embedded benchmark suite. In Proceedings of the Work-
load Characterization, 2001. WWC-4. 2001 IEEE International Workshop.

KISUKI, T., KNIJNENBURG, P. M. W., AND O’BOYLE, M. F. P. 2000. Combined selection of tile sizes and un-
roll factors using iterative compilation. In Proceedings of the 2000 International Conference on Parallel
Architectures and Compilation Techniques. PACT ’00. IEEE Computer Society, Washington, DC, USA,
237–.

KULKARNI, P. A., WHALLEY, D. B., TYSON, G. S., AND DAVIDSON, J. W. 2006. Exhaustive optimization
phase order space exploration. In Proceedings of the International Symposium on Code Generation and
Optimization. CGO ’06.

LATTNER, C. AND ADVE, V. 2004. Llvm: A compilation framework for lifelong program analysis & transfor-
mation. In Proceedings of the international symposium on Code generation and optimization: feedback-
directed and runtime optimization. CGO ’04.

LEATHER, H., BONILLA, E., AND O’BOYLE, M. 2009. Automatic feature generation for machine learning
based optimizing compilation. In Proceedings of the 7th annual IEEE/ACM International Symposium
on Code Generation and Optimization. CGO ’09. 81–91.

LLVM. 2012. http://llvm.org/docs/Passes.html.
PAN, Z. AND EIGENMANN, R. 2006. Fast and effective orchestration of compiler optimizations for automatic
performance tuning. In Proceedings of the International Symposium on Code Generation and Optimiza-
tion. CGO ’06.

PARK, E., KULKARNI, S., AND CAVAZOS, J. 2011. An evaluation of different modeling techniques for iter-
ative compilation. In Proceedings of the 14th international conference on Compilers, architectures and
synthesis for embedded systems. CASES ’11. ACM, New York, NY, USA, 65–74.

POLYBENCH. 2012. http://www.cse.ohio-state.edu/˜pouchet/software/polybench/.

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:23

STEPHENSON, M. AND AMARASINGHE, S. 2005. Predicting unroll factors using supervised classiﬁcation. In

Proceedings of the international symposium on Code generation and optimization. CGO ’05. 123–134.

THOMSON, J., O’BOYLE, M. F. P., FURSIN, G., AND FRANKE, B. 2009. Reducing training time in a one-shot

machine learning-based compiler. In LCPC. 399–407.

TORCZON, L. AND COOPER, K. 2011. Engineering A Compiler 2nd Ed. Morgan Kaufmann Publishers Inc.,

San Francisco, CA, USA.

TOUATI, S.-A.-A. AND BARTHOU, D. 2006. On the decidability of phase ordering problem in optimizing

compilation. In Proceedings of the 3rd conference on Computing frontiers. CF ’06.

TRIANTAFYLLIS, S., VACHHARAJANI, M., VACHHARAJANI, N., AND AUGUST, D. I. 2003. Compiler
optimization-space exploration. In Proceedings of the international symposium on Code generation and
optimization: feedback-directed and runtime optimization. CGO ’03.

WANG, Z. AND O’BOYLE, M. F. 2009. Mapping parallelism to multi-cores: a machine learning based ap-

proach. SIGPLAN Not. 44, 75–84.

ACM Transactions on Architecture and Code Optimization, Vol. 9, No. 4, Article 39, Publication date: March 2010.

